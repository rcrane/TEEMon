programs:
  # Like bio, but with tracepoints. It may catch more than just bio, especially
  # if you have RAID, because requests are getting split and remapped.
  #
  # See:
  # * https://github.com/iovisor/bcc/issues/826
  - name: bio
    metrics:
      histograms:
        - name: bio_latency_seconds
          help: Block IO latency histogram
          table: io_latency
          bucket_type: exp2
          bucket_min: 0
          bucket_max: 26
          bucket_multiplier: 0.000001 # microseconds to seconds
          labels:
            - name: device
              size: 4
              decoders:
                - name: majorminor
            - name: operation
              size: 4
              decoders:
                - name: uint
                - name: static_map
                  static_map:
                    1: read
                    2: write
            - name: bucket
              size: 8
              decoders:
                - name: uint
        - name: bio_size_bytes
          help: Block IO size histogram with kibibyte buckets
          table: io_size
          bucket_type: exp2
          bucket_min: 0
          bucket_max: 15
          bucket_multiplier: 1024 # kibibytes to bytes
          labels:
            - name: device
              size: 4
              decoders:
                - name: majorminor
            - name: operation
              size: 4
              decoders:
                - name: uint
                - name: static_map
                  static_map:
                    1: read
                    2: write
            - name: bucket
              size: 8
              decoders:
                - name: uint
    tracepoints:
      block:block_rq_issue: tracepoint__block__block_rq_issue
      block:block_rq_complete: tracepoint__block__block_rq_complete
    code: |
      #include <linux/blkdev.h>

      typedef struct disk_key {
          u32 dev;
          u8 op;
          u64 slot;
      } disk_key_t;

      // Max number of disks we expect to see on the host
      const u8 max_disks = 255;

      // 27 buckets for latency, max range is 33.6s .. 67.1s
      const u8 max_latency_slot = 26;

      // 16 buckets per disk in kib, max range is 16mib .. 32mib
      const u8 max_size_slot = 15;

      // Histograms to record latencies
      BPF_HISTOGRAM(io_latency, disk_key_t, (max_latency_slot + 2) * max_disks);

      // Histograms to record sizes
      BPF_HISTOGRAM(io_size, disk_key_t, (max_size_slot + 2) * max_disks);

      struct key_t {
          dev_t dev;
          sector_t sector;
      };

      struct val_t {
          u64 start;
          u64 bytes;
      };

      // Hash to temporily hold the start time of each bio request, max 10k in-flight by default
      BPF_HASH(start, struct key_t, struct val_t);

      // Generates function tracepoint__block__block_rq_issue
      TRACEPOINT_PROBE(block, block_rq_issue) {
          // blkid generates these and we're not interested in them
          if (args->dev == 0) {
              return 0;
          }

          struct key_t key = {};
          key.dev = args->dev;
          key.sector = args->sector;

          if (key.sector == -1) {
             key.sector = 0;
          }

          struct val_t val = {};
          val.start = bpf_ktime_get_ns();
          val.bytes = args->bytes;

          start.update(&key, &val);

          return 0;
      }

      // Generates function tracepoint__block__block_rq_complete
      TRACEPOINT_PROBE(block, block_rq_complete) {
          struct key_t key = {};
          key.dev = args->dev;
          key.sector = args->sector;

          if (key.sector == -1) {
             key.sector = 0;
          }

          struct val_t *valp = start.lookup(&key);
          if (valp == 0) {
              return 0; // missed issue
          }

          // Delta in microseconds
          u64 delta = (bpf_ktime_get_ns() - valp->start) / 1000;

          // Latency histogram key
          u64 latency_slot = bpf_log2l(delta);

          // Cap latency bucket at max value
          if (latency_slot > max_latency_slot) {
              latency_slot = max_latency_slot;
          }

          disk_key_t latency_key = {};
          latency_key.slot = latency_slot;
          latency_key.dev = new_encode_dev(args->dev);

          // Size in kibibytes
          u64 size_kib = valp->bytes / 1024;

          // Request size histogram key
          u64 size_slot = bpf_log2(size_kib);

          // Cap latency bucket at max value
          if (size_slot > max_size_slot) {
              size_slot = max_size_slot;
          }

          disk_key_t size_key = {};
          size_key.slot = size_slot;
          size_key.dev = new_encode_dev(args->dev);

          if (args->rwbs[0] == 'W' || args->rwbs[0] == 'S' || args->rwbs[0] == 'F' || args->rwbs[1] == 'W' || args->rwbs[1] == 'S' || args->rwbs[1] == 'F') {
              latency_key.op = 2;
              size_key.op    = 2;
          } else {
              latency_key.op = 1;
              size_key.op    = 1;
          }

          io_latency.increment(latency_key);
          io_size.increment(size_key);

          // Increment sum keys
          latency_key.slot = max_latency_slot + 1;
          io_latency.increment(latency_key, delta);
          size_key.slot = max_size_slot + 1;
          io_size.increment(size_key, size_kib);

          start.delete(&key);

          return 0;
      }
